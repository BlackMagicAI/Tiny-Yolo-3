{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tiny_Yolo3_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlackMagicAI/Tiny-Yolo-3/blob/master/Tiny_Yolo3_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI7i11uAD3hI",
        "colab_type": "text"
      },
      "source": [
        "Tiny yolo3 Colab Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okquTCvC-roF",
        "colab_type": "text"
      },
      "source": [
        "**Outline of Steps**\n",
        "\n",
        "[keras-yolo2](https://github.com/experiencor/keras-yolo2)\n",
        "\n",
        "[keras on google cloud ML](https://stackoverflow.com/questions/41959318/deploying-keras-models-via-google-cloud-ml)\n",
        "\n",
        "[Yolo3 keras github](https://github.com/xiaochus/YOLOv3/blob/master/yad2k.py)\n",
        "\n",
        "[A Practical Guide to Object Detection using the Popular YOLO Framework](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/)\n",
        "\n",
        "\n",
        "\n",
        "##Reference\n",
        "\n",
        "\t@article{YOLOv3,  \n",
        "\t  title={YOLOv3: An Incremental Improvement},  \n",
        "\t  author={J Redmon, A Farhadi },\n",
        "\t  year={2018}\n",
        "    url={https://pjreddie.com/media/files/papers/YOLOv3.pdf}\n",
        "\n",
        "\n",
        "Redmon, Joseph. “Yolo Web: Real-Time Object Detection.” YOLO: Real-Time Object Detection, Joseph Redmon, 2018, pjreddie.com/darknet/yolo/.\n",
        "\n",
        "Based on code from\n",
        "Xiaochus, Larry. “YOLOv3” Github code, Xiaochus, Larry, 2018, https://github.com/xiaochus/YOLOv3.\n",
        "\n",
        "(https://machinethink.net/blog/object-detection-with-yolo/)\n",
        "\n",
        "    + Initialization\n",
        "        + Download COCO detection data from http://cocodataset.org/#download\n",
        "            + http://images.cocodataset.org/zips/train2014.zip <= train images\n",
        "            + http://images.cocodataset.org/zips/val2014.zip <= validation images\n",
        "            + http://images.cocodataset.org/annotations/annotations_trainval2014.zip <= train and validation annotations\n",
        "        + Run this script to convert annotations in COCO format to VOC format\n",
        "            + https://gist.github.com/chicham/6ed3842d0d2014987186#file-coco2pascal-py\n",
        "        + Download pre-trained weights from https://pjreddie.com/darknet/yolo/\n",
        "            + https://pjreddie.com/media/files/yolo.weights\n",
        "        + Specify the directory of train annotations (train_annot_folder) and train images (train_image_folder)\n",
        "        + Specify the directory of validation annotations (valid_annot_folder) and validation images (valid_image_folder)\n",
        "        + Specity the path of pre-trained weights by setting variable *wt_path*\n",
        "    + Construct equivalent network in Keras\n",
        "        + Network arch from https://github.com/pjreddie/darknet/blob/master/cfg/yolo-voc.cfg\n",
        "    + Load the pretrained weights\n",
        "    + Perform training \n",
        "    + Perform detection on an image with newly trained weights\n",
        "    + Perform detection on an video with newly trained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI-sPnTJ5x1v",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTANT!!!\n",
        "Read comment in next cell before procedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mku_NRbwiWWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!!!!IMPORTANT - RUN THIS CELL FIRST AND RESTART THE RUNTIME BEOFORE RUNNING THE OTHER CELLS\n",
        "!pip install tensorflow==1.15.3 #this works"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnFPqCe1-vpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/xiaochus/YOLOv3.git\n",
        "  \n",
        "##Make training data directories\n",
        "!mkdir yolo3_tiny\n",
        "\n",
        "%cd yolo3_tiny\n",
        "\n",
        "# Make image input and output directories\n",
        "!mkdir images\n",
        "!mkdir out\n",
        "\n",
        "!cp ../YOLOv3/images/test/*.jpg images\n",
        "\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg\n",
        "!wget https://pjreddie.com/media/files/yolov3-tiny.weights\n",
        "\n",
        "# copy classes file to yolo3_tiny directory\n",
        "!cp ../YOLOv3/data/coco_classes.txt coco_classes.txt\n",
        "\n",
        "#Get custom fonts for image annotations\n",
        "!wget -O font.zip https://fonts.google.com/download?family=Ubuntu\n",
        "!unzip font.zip -d fonts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL80azP2-roO",
        "colab_type": "text"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riKx6JoIHcRB",
        "colab_type": "text"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrMExESSyrD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c05278d-865f-41c0-a870-266be7b8d7e7"
      },
      "source": [
        "#numpy is a math library use to create and manipulate matricies\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, Reshape, LeakyReLU, MaxPooling2D, UpSampling2D, Lambda\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# ML Cloud serving imports\n",
        "from tensorflow.python.saved_model import builder as saved_model_builder\n",
        "from tensorflow.python.saved_model import tag_constants, signature_constants, signature_def_utils_impl, utils\n",
        "from functools import partial\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxeNCOF0h_rF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1df92c9d-b24f-4748-a680-a38ffb4e4c05"
      },
      "source": [
        "# print(\"Keras version \" + keras.__version__)\n",
        "print(\"Tensorflow version\" + tf.__version__) #should be 1.15.3\n",
        "!python --version #3.6.9 works"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version1.15.3\n",
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-04T00:18:52.075535",
          "start_time": "2018-04-04T00:18:52.057712"
        },
        "scrolled": true,
        "id": "1qMSrBu6-ros",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABELS = ['raccoon', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
        "# LABELS = ['person']\n",
        "\n",
        "IMAGE_H, IMAGE_W = 416, 416\n",
        "GRID_H,  GRID_W  = 13 , 13\n",
        "BOX              = 5\n",
        "CLASS            = len(LABELS)\n",
        "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
        "OBJ_THRESHOLD    = 0.3#0.5\n",
        "NMS_THRESHOLD    = 0.3#0.45\n",
        "ANCHORS          = [10,14, 23,27, 37,58, 81,82, 135,169, 344,319]\n",
        "\n",
        "NO_OBJECT_SCALE  = 1.0\n",
        "OBJECT_SCALE     = 5.0\n",
        "COORD_SCALE      = 1.0\n",
        "CLASS_SCALE      = 1.0\n",
        "\n",
        "BATCH_SIZE       = 16\n",
        "WARM_UP_BATCHES  = 0\n",
        "TRUE_BOX_BUFFER  = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-04T00:18:52.981155",
          "start_time": "2018-04-04T00:18:52.978076"
        },
        "id": "1-6w_8o6-ro5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wt_path = 'yolov2.weights'  \n",
        "# wt_path = 'yolov3.weights'\n",
        "wt_path = 'yolov3-tiny.weights' \n",
        "train_image_folder = './data/coco/train/'\n",
        "train_annot_folder = './data/coco/trainann/'\n",
        "valid_image_folder = './data/coco/val/'\n",
        "valid_annot_folder = './data/coco/valann/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCE0ttCg-rpH",
        "colab_type": "text"
      },
      "source": [
        "# Construct the network - Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-04T00:18:53.978220",
          "start_time": "2018-04-04T00:18:53.967537"
        },
        "id": "tV5l3QUz-rpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
        "def space_to_depth_x2(x):\n",
        "    return tf.space_to_depth(x, block_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzhC7RI_jIJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights_file.close()\n",
        "# weights function\n",
        "def setWeights(filters ,size ,count , input_shape, weights_file, doBatch):\n",
        "  # ********Start weights code*************\n",
        "  prev_layer_shape = K.int_shape(input_shape)\n",
        "\n",
        "  weights_shape = (size, size, prev_layer_shape[-1], filters)\n",
        "  darknet_w_shape = (filters, weights_shape[2], size, size)\n",
        "  weights_size = np.product(weights_shape)\n",
        "\n",
        "  conv_bias = np.ndarray(\n",
        "    shape=(filters, ),\n",
        "    dtype='float32',\n",
        "    buffer=weights_file.read(filters * 4))\n",
        "  count += filters\n",
        "\n",
        "  conv_weights = []\n",
        "  bn_weight_list = []\n",
        "\n",
        "# apply batch normalization of doBatch flag is true\n",
        "  if doBatch:\n",
        "\n",
        "    bn_weights = np.ndarray(\n",
        "        shape=(3, filters),\n",
        "        dtype='float32',\n",
        "        buffer=weights_file.read(filters * 12))\n",
        "    count += 3 * filters\n",
        "\n",
        "    # TODO: Keras BatchNormalization mistakenly refers to var\n",
        "    # as std.\n",
        "    bn_weight_list = [\n",
        "        bn_weights[0],  # scale gamma\n",
        "        conv_bias,  # shift beta\n",
        "        bn_weights[1],  # running mean\n",
        "        bn_weights[2]  # running var\n",
        "    ]\n",
        "\n",
        "  conv_weights = np.ndarray(\n",
        "      shape=darknet_w_shape,\n",
        "      dtype='float32',\n",
        "      buffer=weights_file.read(weights_size * 4))\n",
        "  count += weights_size\n",
        "\n",
        "  conv_weights = np.transpose(conv_weights, [2, 3, 1, 0])\n",
        "\n",
        "  #conv_weights = []\n",
        "  if doBatch:\n",
        "    conv_weights = [conv_weights] #if BatchNormalization use this\n",
        "  else:\n",
        "    conv_weights = [conv_weights, conv_bias] #else use this\n",
        "\n",
        "  return conv_weights, bn_weight_list, count\n",
        "\n",
        "# ********End weights code*************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1h4QrY5SzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34e9f6fe-4547-467d-cffc-d08691ca4069"
      },
      "source": [
        "# https://github.com/xiaochus/YOLOv3/blob/master/yad2k.py\n",
        "weights_file = open(wt_path, 'rb')\n",
        "weights_header = np.ndarray(\n",
        "        shape=(5, ), dtype='int32', buffer=weights_file.read(20))\n",
        "print('Weights Header: ', weights_header)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights Header:  [       0        2        0 32013312        0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-04-04T00:18:58.022959",
          "start_time": "2018-04-04T00:18:55.740759"
        },
        "code_folding": [],
        "id": "Mb0WN8hc-rpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "828950ef-05f7-422e-ca61-7559f3bd8dc1"
      },
      "source": [
        "sess = tf.Session()\n",
        "from keras import backend as K\n",
        "K.set_session(sess)\n",
        "# K.set_learning_phase(0) #all new operations will be in test mode from now on - The learning phase flag is a bool tensor (0 = test, 1 = train) to be passed as input to any Keras function that uses a different behavior at train time and test time\n",
        "\n",
        "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3), name='input_1')\n",
        "true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
        "weight_decay = 0.0005\n",
        "\n",
        "#Initialize filter count variable\n",
        "count = 0\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(16, 3, count, input_image ,weights_file , True)\n",
        "\n",
        "\n",
        "# Layer 1\n",
        "x = Conv2D(16, (3,3), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_1', use_bias=False)(input_image)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_1')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(32 ,3 ,count ,x ,weights_file , True)\n",
        "\n",
        "# Layer 2\n",
        "x = Conv2D(32, (3,3), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_2', use_bias=False)(x)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_2')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(64 ,3 ,count , x,weights_file , True)\n",
        "\n",
        "# Layer 3\n",
        "x = Conv2D(64, (3,3), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_3', use_bias=False)(x)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_3')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(128 ,3 ,count , x,weights_file , True)\n",
        "\n",
        "# Layer 4\n",
        "x = Conv2D(128, (3,3), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_4', use_bias=False)(x)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_4')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(256 ,3 ,count ,x ,weights_file , True)\n",
        "\n",
        "# Layer 5\n",
        "x = Conv2D(256, (3,3), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_5', use_bias=False)(x)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_5')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "convd5 = x\n",
        "\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(512 ,3 ,count ,x ,weights_file , True)\n",
        "\n",
        "# Layer 6\n",
        "x = Conv2D(512, (3,3), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_6', use_bias=False)(x)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_6')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(padding='same', pool_size=(2, 2), strides=(1,1))(x)\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(1024 ,3 ,count ,x ,weights_file , True)\n",
        "\n",
        "# Layer 7\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_7', use_bias=False)(x)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_7')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "route7 = x\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(256 ,1 ,count ,x ,weights_file , True)\n",
        "\n",
        "# Layer 8\n",
        "x = Conv2D(256, (1,1), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_8', use_bias=False)(x)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_8')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "convd8 = x\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(512 ,3 ,count ,x ,weights_file , True)\n",
        "\n",
        "# Layer 9\n",
        "x = Conv2D(512, (3,3), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_9', use_bias=False)(x)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_9')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(255 ,1 ,count ,x ,weights_file , False)\n",
        "\n",
        "# Layer 10\n",
        "x = Conv2D(255, (1,1), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same',name='conv_10', use_bias=True)(x)\n",
        "n1, n2 = int(x.shape[1]), int(x.shape[2])\n",
        "# x = Activation('linear')(x)\n",
        "\n",
        "convd10 = x\n",
        "\n",
        "# Layer 11 - yolo\n",
        "n1, n2 = int(x.shape[1]), int(x.shape[2])\n",
        "n3 = 3\n",
        "classes = 80\n",
        "n4 = (4 + 1 + classes)\n",
        "yolo0 = Reshape((n1, n2, n3, n4))(x)\n",
        "\n",
        "# Layer 12 - route\n",
        "# https://github.com/AlexeyAB/darknet/issues/279#issuecomment-397248821\n",
        "# Get input for next Conv layer from layer -4 index previous = Layer 7\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(128 ,1 ,count ,convd8 ,weights_file , True)\n",
        "\n",
        "# Layer 13 - route layer\n",
        "x = Conv2D(128, (1,1), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_13', use_bias=False)(convd8)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_13')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 14 - upsample\n",
        "# x = ZeroPadding2D(((1, 0), (1, 0)))(convd10) # Adjust padding model for darknet.\n",
        "x = UpSampling2D(size=(2, 2))(x)\n",
        "\n",
        "# Layer 15 - route\n",
        "# https://github.com/AlexeyAB/darknet/issues/279#issuecomment-397248821\n",
        "# Get input for next Conv layer from layer -1 index previous = Layer 14 and Layer 8\n",
        "# skip_connection = Lambda(space_to_depth_x2)(x)\n",
        "# x = concatenate([route8, skip_connection])\n",
        "x = concatenate([convd5, x])\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(256 ,3 ,count ,x ,weights_file , True)\n",
        "\n",
        "# Layer 16\n",
        "x = Conv2D(256, (3,3), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_16', use_bias=False)(x)\n",
        "x = BatchNormalization(weights=bn_weight_list, name='norm_16')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# ******** Apply weights function *************\n",
        "conv_weights, bn_weight_list, count = setWeights(255 ,1 ,count ,x ,weights_file , False)\n",
        "\n",
        "# Layer 17\n",
        "x = Conv2D(255, (1,1), strides=(1,1), kernel_regularizer=l2(weight_decay), weights=conv_weights, padding='same', name='conv_17', use_bias=True)(x)\n",
        "\n",
        "# Layer 18 - yolo\n",
        "n1, n2 = int(x.shape[1]), int(x.shape[2])\n",
        "yolo1 = Reshape((n1, n2, 3, 85))(x)\n",
        "\n",
        "# Create and save model.\n",
        "model = Model(inputs=[input_image],  outputs=[yolo0, yolo1])\n",
        "\n",
        "# Export to hd5 file\n",
        "model.save('{}'.format('yolotest.h5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjUcAhwj5l81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp yolotest.h5 ../YOLOv3/data/yolo.h5\n",
        "#%cd ../\n",
        "#!rm -rf yolo3_tiny\n",
        "#!rm -rf YOLOv3\n",
        "#!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-26T12:34:03.819802Z",
          "start_time": "2017-11-26T12:34:03.786125Z"
        },
        "scrolled": false,
        "id": "BqSxALZH-rpd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f47dc239-aece-4f40-b3d8-79ec17481c2f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 416, 416, 16) 432         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_1 (BatchNormalization)     (None, 416, 416, 16) 64          conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 416, 416, 16) 0           norm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 208, 208, 16) 0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 208, 208, 32) 4608        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_2 (BatchNormalization)     (None, 208, 208, 32) 128         conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 208, 208, 32) 0           norm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 104, 104, 32) 0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 104, 104, 64) 18432       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_3 (BatchNormalization)     (None, 104, 104, 64) 256         conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 104, 104, 64) 0           norm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 52, 52, 64)   0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_4 (Conv2D)                 (None, 52, 52, 128)  73728       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_4 (BatchNormalization)     (None, 52, 52, 128)  512         conv_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 52, 52, 128)  0           norm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 26, 26, 128)  0           leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_5 (Conv2D)                 (None, 26, 26, 256)  294912      max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_5 (BatchNormalization)     (None, 26, 26, 256)  1024        conv_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 26, 26, 256)  0           norm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 256)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_6 (Conv2D)                 (None, 13, 13, 512)  1179648     max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_6 (BatchNormalization)     (None, 13, 13, 512)  2048        conv_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 13, 13, 512)  0           norm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 13, 13, 512)  0           leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_7 (Conv2D)                 (None, 13, 13, 1024) 4718592     max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_7 (BatchNormalization)     (None, 13, 13, 1024) 4096        conv_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 13, 13, 1024) 0           norm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_8 (Conv2D)                 (None, 13, 13, 256)  262144      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_8 (BatchNormalization)     (None, 13, 13, 256)  1024        conv_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 13, 13, 256)  0           norm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_13 (Conv2D)                (None, 13, 13, 128)  32768       leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_13 (BatchNormalization)    (None, 13, 13, 128)  512         conv_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 13, 13, 128)  0           norm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 26, 26, 128)  0           leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 26, 26, 384)  0           leaky_re_lu_5[0][0]              \n",
            "                                                                 up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_9 (Conv2D)                 (None, 13, 13, 512)  1179648     leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_16 (Conv2D)                (None, 26, 26, 256)  884736      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_9 (BatchNormalization)     (None, 13, 13, 512)  2048        conv_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "norm_16 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 13, 13, 512)  0           norm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 26, 26, 256)  0           norm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_10 (Conv2D)                (None, 13, 13, 255)  130815      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_17 (Conv2D)                (None, 26, 26, 255)  65535       leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 13, 13, 3, 85 0           conv_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 26, 26, 3, 85 0           conv_17[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,858,734\n",
            "Trainable params: 8,852,366\n",
            "Non-trainable params: 6,368\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcuXWQREowAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "716a3330-be0c-430c-e2e9-f69f219975a2"
      },
      "source": [
        "# Check to see if all weights have been read.\n",
        "remaining_weights = len(weights_file.read()) / 4\n",
        "\n",
        "print('Read {} of {} from Darknet weights.'.format(count, count +\n",
        "remaining_weights))\n",
        "\n",
        "weights_file.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 8858734 of 8858734.0 from Darknet weights.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3R_4pVg9z6C",
        "colab_type": "text"
      },
      "source": [
        "##Perform detection on image\n",
        "\n",
        "[Based on code from xiaochus github repo](https://github.com/xiaochus/YOLOv3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUi1RcdN-bxX",
        "colab_type": "text"
      },
      "source": [
        "###Load yolo model from file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce3wdQ3D-gWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "63015006-4ec0-4ada-bbf5-d133138cf97c"
      },
      "source": [
        "yolo = load_model('yolotest.h5')\n",
        "# yolo = model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsoowMPaRrPt",
        "colab_type": "text"
      },
      "source": [
        "###Image processing functions\n",
        "[Based on code from xiaochus github repo](https://github.com/xiaochus/YOLOv3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJu86g8_hMTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# obj_threshold\n",
        "# t1 = 0.6\n",
        "t1 = 0.1\n",
        "# nms_threshold\n",
        "t2 = 0.5\n",
        "    \n",
        "def sigmoid(x):\n",
        "        \"\"\"sigmoid.\n",
        "\n",
        "        # Arguments\n",
        "            x: Tensor.\n",
        "\n",
        "        # Returns\n",
        "            numpy ndarray.\n",
        "        \"\"\"\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def process_feats(out, anchors, mask):\n",
        "    \"\"\"process output features.\n",
        "\n",
        "    # Arguments\n",
        "        out: Tensor (N, N, 3, 4 + 1 +80), output feature map of yolo.\n",
        "        anchors: List, anchors for box.\n",
        "        mask: List, mask for anchors.\n",
        "\n",
        "    # Returns\n",
        "        boxes: ndarray (N, N, 3, 4), x,y,w,h for per box.\n",
        "        box_confidence: ndarray (N, N, 3, 1), confidence for per box.\n",
        "        box_class_probs: ndarray (N, N, 3, 80), class probs for per box.\n",
        "    \"\"\"\n",
        "    grid_h, grid_w, num_boxes = map(int, out.shape[1: 4])\n",
        "\n",
        "    anchors = [anchors[i] for i in mask]\n",
        "    anchors_tensor = np.array(anchors).reshape(1, 1, len(anchors), 2)\n",
        "\n",
        "    # Reshape to batch, height, width, num_anchors, box_params.\n",
        "    out = out[0]\n",
        "    box_xy = sigmoid(out[..., :2])\n",
        "    box_wh = np.exp(out[..., 2:4])\n",
        "    box_wh = box_wh * anchors_tensor\n",
        "\n",
        "    box_confidence = sigmoid(out[..., 4])\n",
        "    box_confidence = np.expand_dims(box_confidence, axis=-1)\n",
        "    box_class_probs = sigmoid(out[..., 5:])\n",
        "\n",
        "    col = np.tile(np.arange(0, grid_w), grid_w).reshape(-1, grid_w)\n",
        "    row = np.tile(np.arange(0, grid_h).reshape(-1, 1), grid_h)\n",
        "\n",
        "    col = col.reshape(grid_h, grid_w, 1, 1).repeat(3, axis=-2)\n",
        "    row = row.reshape(grid_h, grid_w, 1, 1).repeat(3, axis=-2)\n",
        "    grid = np.concatenate((col, row), axis=-1)\n",
        "\n",
        "    box_xy += grid\n",
        "    box_xy /= (grid_w, grid_h)\n",
        "    box_wh /= (416, 416)\n",
        "    box_xy -= (box_wh / 2.)\n",
        "    boxes = np.concatenate((box_xy, box_wh), axis=-1)\n",
        "\n",
        "    return boxes, box_confidence, box_class_probs\n",
        "    \n",
        "def nms_boxes(boxes, scores):\n",
        "    \"\"\"Suppress non-maximal boxes.\n",
        "\n",
        "    # Arguments\n",
        "        boxes: ndarray, boxes of objects.\n",
        "        scores: ndarray, scores of objects.\n",
        "\n",
        "    # Returns\n",
        "        keep: ndarray, index of effective boxes.\n",
        "    \"\"\"\n",
        "    x = boxes[:, 0]\n",
        "    y = boxes[:, 1]\n",
        "    w = boxes[:, 2]\n",
        "    h = boxes[:, 3]\n",
        "\n",
        "    areas = w * h\n",
        "    order = scores.argsort()[::-1]\n",
        "\n",
        "    keep = []\n",
        "    while order.size > 0:\n",
        "        i = order[0]\n",
        "        keep.append(i)\n",
        "\n",
        "        xx1 = np.maximum(x[i], x[order[1:]])\n",
        "        yy1 = np.maximum(y[i], y[order[1:]])\n",
        "        xx2 = np.minimum(x[i] + w[i], x[order[1:]] + w[order[1:]])\n",
        "        yy2 = np.minimum(y[i] + h[i], y[order[1:]] + h[order[1:]])\n",
        "\n",
        "        w1 = np.maximum(0.0, xx2 - xx1 + 1)\n",
        "        h1 = np.maximum(0.0, yy2 - yy1 + 1)\n",
        "        inter = w1 * h1\n",
        "\n",
        "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
        "        inds = np.where(ovr <= t2)[0]\n",
        "        order = order[inds + 1]\n",
        "\n",
        "    keep = np.array(keep)\n",
        "\n",
        "    return keep\n",
        "      \n",
        "def filter_boxes(boxes, box_confidences, box_class_probs):\n",
        "    \"\"\"Filter boxes with object threshold.\n",
        "\n",
        "    # Arguments\n",
        "        boxes: ndarray, boxes of objects.\n",
        "        box_confidences: ndarray, confidences of objects.\n",
        "        box_class_probs: ndarray, class_probs of objects.\n",
        "\n",
        "    # Returns\n",
        "        boxes: ndarray, filtered boxes.\n",
        "        classes: ndarray, classes for boxes.\n",
        "        scores: ndarray, scores for boxes.\n",
        "    \"\"\"\n",
        "    box_scores = box_confidences * box_class_probs\n",
        "    box_classes = np.argmax(box_scores, axis=-1)\n",
        "    box_class_scores = np.max(box_scores, axis=-1)\n",
        "    pos = np.where(box_class_scores >= t1)\n",
        "\n",
        "    boxes = boxes[pos]\n",
        "    classes = box_classes[pos]\n",
        "    scores = box_class_scores[pos]\n",
        "\n",
        "    return boxes, classes, scores\n",
        "      \n",
        "def yolo_out(outs, shape):\n",
        "    \"\"\"Process output of yolo base net.\n",
        "\n",
        "    # Argument:\n",
        "        outs: output of yolo base net.\n",
        "        shape: shape of original image.\n",
        "\n",
        "    # Returns:\n",
        "        boxes: ndarray, boxes of objects.\n",
        "        classes: ndarray, classes of objects.\n",
        "        scores: ndarray, scores of objects.\n",
        "    \"\"\"\n",
        "    masks = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
        "    anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],\n",
        "               [59, 119], [116, 90], [156, 198], [373, 326]]\n",
        "\n",
        "    boxes, classes, scores = [], [], []\n",
        "\n",
        "    for out, mask in zip(outs, masks):\n",
        "        b, c, s = process_feats(out, anchors, mask)\n",
        "        b, c, s = filter_boxes(b, c, s)\n",
        "        boxes.append(b)\n",
        "        classes.append(c)\n",
        "        scores.append(s)\n",
        "\n",
        "    boxes = np.concatenate(boxes)\n",
        "    classes = np.concatenate(classes)\n",
        "    scores = np.concatenate(scores)\n",
        "\n",
        "    # Scale boxes back to original image shape.\n",
        "    width, height = shape[0], shape[1]\n",
        "    image_dims = [width, height, width, height]\n",
        "    boxes = boxes * image_dims\n",
        "\n",
        "    nboxes, nclasses, nscores = [], [], []\n",
        "    for c in set(classes):\n",
        "        inds = np.where(classes == c)\n",
        "        b = boxes[inds]\n",
        "        c = classes[inds]\n",
        "        s = scores[inds]\n",
        "\n",
        "        keep = nms_boxes(b, s)\n",
        "\n",
        "        nboxes.append(b[keep])\n",
        "        nclasses.append(c[keep])\n",
        "        nscores.append(s[keep])\n",
        "\n",
        "    if not nclasses and not nscores:\n",
        "        return None, None, None\n",
        "\n",
        "    boxes = np.concatenate(nboxes)\n",
        "    classes = np.concatenate(nclasses)\n",
        "    scores = np.concatenate(nscores)\n",
        "\n",
        "    return boxes, classes, scores\n",
        "\n",
        "def draw(image, boxes, scores, classes, all_classes):\n",
        "    \n",
        "  \"\"\"Draw the boxes on the image.\n",
        "    # Argument:\n",
        "        image: original image.\n",
        "        boxes: ndarray, boxes of objects.\n",
        "        classes: ndarray, classes of objects.\n",
        "        scores: ndarray, scores of objects.\n",
        "        all_classes: all classes name.\n",
        "  \"\"\"\n",
        "#uncomment to use a custom font uploaded to this notebook directory\n",
        "  fnt =ImageFont.truetype('./fonts/Ubuntu-Bold.ttf', 18)\n",
        "\n",
        "  for box, score, cl in zip(boxes, scores, classes):\n",
        "  \n",
        "      x, y, w, h = box\n",
        "\n",
        "      top = max(0, np.floor(x + 0.5).astype(int))\n",
        "      left = max(0, np.floor(y + 0.5).astype(int))\n",
        "      right = min(image.size[0], np.floor(x + w + 0.5).astype(int))\n",
        "      bottom = min(image.size[1], np.floor(y + h + 0.5).astype(int))\n",
        "\n",
        "      draw = ImageDraw.Draw(image)\n",
        "      draw.rectangle([(top, left), (right, bottom)], outline=(0,255,0))#blue rectangle\n",
        "      draw.text((top, left - 6), '{0} {1:.2f}'.format(all_classes[cl], score), font=fnt, fill=(0, 0, 255))\n",
        "#      draw.text((top, left - 6), '{0} {1:.2f}'.format(all_classes[cl], score), fill=(0, 0, 255))\n",
        "#         draw.rectangle([(left, top), (right, bottom)], outline=(0,0,255))#blue rectangle\n",
        "      print('class: {0}, score: {1:.2f}'.format(all_classes[cl], score))\n",
        "      print('box coordinate x,y,w,h: {0}'.format(box))\n",
        "\n",
        "  print()\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VLbvZ1G-9wm",
        "colab_type": "text"
      },
      "source": [
        "###Load Image\n",
        "Resize, reduce and expand image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX46M8wJ-aEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pick one image to process by uncommenting it\n",
        "#input_image_name = 'person.jpg'\n",
        "#input_image_name = 'giraffe.jpg'\n",
        "#input_image_name = 'dog.jpg'\n",
        "#input_image_name = 'eagle.jpg'\n",
        "#input_image_name = 'horses.jpg'\n",
        "input_image_name = 'toysoldiers.jpg'\n",
        "\n",
        "size = (416, 416)\n",
        "image_src = Image.open(\"images/\" + input_image_name)\n",
        "orig_size = image_src.size\n",
        "image_thumb = image_src.resize(size, Image.BICUBIC)\n",
        "image_thumb.save(\"out/thumb_\" + input_image_name, \"JPEG\") #save thumbnail version\n",
        "image = np.array(image_thumb, dtype='float32')\n",
        "image /= 255.\n",
        "image = np.expand_dims(image, axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVQv7Vl1GBEF",
        "colab_type": "text"
      },
      "source": [
        "###Get prediction output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zheby-MEEXbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b4785e43-599a-4afd-c855-a4d40eec1c60"
      },
      "source": [
        "# Raw Prediction Output\n",
        "output = yolo.predict(image)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5icYPd8RTjae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "41bb7b31-1bfc-4062-c606-1eaf411a68c3"
      },
      "source": [
        "with open('coco_classes.txt') as f:\n",
        "    class_names = f.readlines()\n",
        "all_classes = [c.strip() for c in class_names]\n",
        "\n",
        "# Processed Output\n",
        "image_thumb = Image.open(\"out/thumb_\" + input_image_name) #open thumbnail image\n",
        "thumb_size = image_thumb.size\n",
        "boxes, classes, scores = yolo_out(output, thumb_size)  #process thumbnail image\n",
        "#boxes, classes, scores = yolo_out(output, orig_size)\n",
        "if boxes is not None:\n",
        "  draw(image_thumb, boxes, scores, classes, all_classes) #annotate thumbnail image\n",
        "  #draw(image_src, boxes, scores, classes, all_classes)\n",
        "\n",
        "# Display processed image output\n",
        "# image_src.show()  \n",
        "#image_src.save(\"out/\" + input_image_name, \"JPEG\")\n",
        "image_thumb.save(\"out/\" + input_image_name, \"JPEG\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class: person, score: 0.59\n",
            "box coordinate x,y,w,h: [168.31674671 140.2295084   77.26895118 123.73338103]\n",
            "class: person, score: 0.41\n",
            "box coordinate x,y,w,h: [351.90662384  35.0162816   69.95378542 116.17601037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}